{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f84e4c1-2693-4e7d-86e1-c153fbe72bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import numpy as np\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "import xarray\n",
    "from mpi4py import MPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3401b431-34ba-4cc9-ac8e-82e16bb98e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These paths will need to be altered to fit the current environment\n",
    "\n",
    "# data and model paths\n",
    "data_path = \"/home/jovyan/shared/fourcastnet/FourCastNet/data/FCN_ERA5_data_v0/out_of_sample\"\n",
    "d_2 = '/home/jovyan/ccai_demo/data/FCN_ERA5_data_v0/out_of_sample'\n",
    "data_file = os.path.join(data_path, \"2018.h5\")\n",
    "data_file2 = os.path.join(d_2, \"2018.h5\")\n",
    "\n",
    "#model_path = \"/home/jovyan/new_checkpoints/backbone1.ckpt\"\n",
    "model_path = \"/home/jovyan/shared/fourcastnet/FourCastNet/model_weights/FCN_weights_v0/backbone.ckpt\"\n",
    "global_means_path = \"/home/jovyan/shared/fourcastnet/FourCastNet/additional/stats_v0/global_means.npy\"\n",
    "global_stds_path = \"/home/jovyan/shared/fourcastnet/FourCastNet/additional/stats_v0/global_stds.npy\"\n",
    "time_means_path = \"/home/jovyan/shared/fourcastnet/FourCastNet/additional/stats_v0/time_means.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e898286-5e9e-441b-9e4a-c3bc0a9828f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The ordering of atmospheric variables along the channel dimension is as follows:\n",
    "'''\n",
    "variables = ['u10',\n",
    "             'v10',\n",
    "             't2m',\n",
    "             'sp',\n",
    "             'msl',\n",
    "             't850',\n",
    "             'u1000',\n",
    "             'v1000',\n",
    "             'z1000',\n",
    "             'u850',\n",
    "             'v850',\n",
    "             'z850',\n",
    "             'u500',\n",
    "             'v500',\n",
    "             'z500',\n",
    "             't500',\n",
    "             'z50' ,\n",
    "             'r500',\n",
    "             'r850',\n",
    "             'tcwv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976a2dca-8af0-4281-822e-220a240323d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from FourCastNet.utils.YParams import YParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e0fea7-d969-4fcf-af0e-8edb46072c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = \"/home/jovyan/FourCastNet/config/AFNO.yaml\"\n",
    "config_name = \"afno_backbone\"\n",
    "params = YParams(config_file, config_name)\n",
    "print(\"Model architecture used = {}\".format(params[\"nettype\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f91e85-40ed-4741-ba95-899727fd369a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import model\n",
    "from FourCastNet.networks.afnonet import AFNONet\n",
    "from collections import OrderedDict\n",
    "\n",
    "def load_model(model, params, checkpoint_file):\n",
    "    ''' helper function to load model weights '''\n",
    "    checkpoint_fname = checkpoint_file\n",
    "    checkpoint = torch.load(checkpoint_fname)\n",
    "    try:\n",
    "        ''' FourCastNet is trained with distributed data parallel\n",
    "            (DDP) which prepends 'module' to all keys. Non-DDP\n",
    "            models need to strip this prefix '''\n",
    "        new_state_dict = OrderedDict()\n",
    "        for key, val in checkpoint['model_state'].items():\n",
    "            name = key[7:]\n",
    "            if name != 'ged':\n",
    "                new_state_dict[name] = val\n",
    "        model.load_state_dict(new_state_dict)\n",
    "    except:\n",
    "        model.load_state_dict(checkpoint['model_state'])\n",
    "    model.eval() # set to inference mode\n",
    "    return model\n",
    "\n",
    "device = torch.cuda.current_device() if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# in and out channels: FourCastNet uses 20 input channels corresponding to 20 prognostic variables\n",
    "in_channels = np.array(params.in_channels)\n",
    "out_channels = np.array(params.out_channels)\n",
    "params['N_in_channels'] = len(in_channels)\n",
    "params['N_out_channels'] = len(out_channels)\n",
    "params.means = np.load(global_means_path)[0, out_channels] # for normalizing data with precomputed train stats\n",
    "params.stds = np.load(global_stds_path)[0, out_channels]\n",
    "params.time_means = np.load(time_means_path)[0, out_channels]\n",
    "\n",
    "# load the model\n",
    "if params.nettype == 'afno':\n",
    "    model = AFNONet(params).to(device)  # AFNO model\n",
    "else:\n",
    "    raise Exception(\"not implemented\")\n",
    "# load saved model weights\n",
    "model = load_model(model, params, model_path)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b030d09-2317-4321-8e5b-b09ca90c56bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# move normalization tensors to gpu\n",
    "# load time means: represents climatology\n",
    "img_shape_x = 720\n",
    "img_shape_y = 1440\n",
    "\n",
    "# means and stds over training data\n",
    "means = params.means\n",
    "stds = params.stds\n",
    "\n",
    "# load climatological means\n",
    "time_means = params.time_means # temporal mean (for every pixel)\n",
    "m = torch.as_tensor((time_means - means)/stds)[:, 0:img_shape_x]\n",
    "m = torch.unsqueeze(m, 0)\n",
    "# these are needed to compute ACC and RMSE metrics\n",
    "m = m.to(device, dtype=torch.float)\n",
    "std = torch.as_tensor(stds[:,0,0]).to(device, dtype=torch.float)\n",
    "\n",
    "print(\"Shape of time means = {}\".format(m.shape))\n",
    "print(\"Shape of std = {}\".format(std.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6084f243-5861-4618-8e0d-efb72f510448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define metrics from definitions\n",
    "def lat(j: torch.Tensor, num_lat: int) -> torch.Tensor:\n",
    "    return 90. - j * 180./float(num_lat-1)\n",
    "\n",
    "def latitude_weighting_factor(j: torch.Tensor, num_lat: int, s: torch.Tensor) -> torch.Tensor:\n",
    "    return num_lat * torch.cos(3.1416/180. * lat(j, num_lat))/s\n",
    "\n",
    "def weighted_rmse_channels(pred: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
    "    #takes in arrays of size [n, c, h, w]  and returns latitude-weighted rmse for each channel\n",
    "    num_lat = pred.shape[2]\n",
    "    lat_t = torch.arange(start=0, end=num_lat, device=pred.device)\n",
    "    s = torch.sum(torch.cos(3.1416/180. * lat(lat_t, num_lat)))\n",
    "    weight = torch.reshape(latitude_weighting_factor(lat_t, num_lat, s), (1, 1, -1, 1))\n",
    "    result = torch.sqrt(torch.mean(weight * (pred - target)**2., dim=(-1,-2)))\n",
    "    return result\n",
    "\n",
    "def weighted_acc_channels(pred: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
    "    #takes in arrays of size [n, c, h, w]  and returns latitude-weighted acc for each channel\n",
    "    num_lat = pred.shape[2]\n",
    "    lat_t = torch.arange(start=0, end=num_lat, device=pred.device)\n",
    "    s = torch.sum(torch.cos(3.1416/180. * lat(lat_t, num_lat)))\n",
    "    weight = torch.reshape(latitude_weighting_factor(lat_t, num_lat, s), (1, 1, -1, 1))\n",
    "    result = torch.sum(weight * pred * target, dim=(-1,-2)) / torch.sqrt(torch.sum(weight * pred * pred, dim=(-1,-2)) * torch.sum(weight * target *\n",
    "    target, dim=(-1,-2)))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e860c8c9-4999-4613-8f8c-cf3f2fe56d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BSD 3-Clause License\n",
    "#\n",
    "#Copyright (c) 2022, FourCastNet authors\n",
    "#All rights reserved.\n",
    "#\n",
    "#Redistribution and use in source and binary forms, with or without\n",
    "#modification, are permitted provided that the following conditions are met:\n",
    "#\n",
    "#1. Redistributions of source code must retain the above copyright notice, this\n",
    "#   list of conditions and the following disclaimer.\n",
    "#\n",
    "#2. Redistributions in binary form must reproduce the above copyright notice,\n",
    "#   this list of conditions and the following disclaimer in the documentation\n",
    "#   and/or other materials provided with the distribution.\n",
    "#\n",
    "#3. Neither the name of the copyright holder nor the names of its\n",
    "#   contributors may be used to endorse or promote products derived from\n",
    "#   this software without specific prior written permission.\n",
    "#\n",
    "#THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n",
    "#AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n",
    "#IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\n",
    "#DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\n",
    "#FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\n",
    "#DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\n",
    "#SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\n",
    "#CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\n",
    "#OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n",
    "#OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n",
    "#\n",
    "#The code was authored by the following people:\n",
    "#\n",
    "#Jaideep Pathak - NVIDIA Corporation\n",
    "#Shashank Subramanian - NERSC, Lawrence Berkeley National Laboratory\n",
    "#Peter Harrington - NERSC, Lawrence Berkeley National Laboratory\n",
    "#Sanjeev Raja - NERSC, Lawrence Berkeley National Laboratory \n",
    "#Ashesh Chattopadhyay - Rice University \n",
    "#Morteza Mardani - NVIDIA Corporation \n",
    "#Thorsten Kurth - NVIDIA Corporation \n",
    "#David Hall - NVIDIA Corporation \n",
    "#Zongyi Li - California Institute of Technology, NVIDIA Corporation \n",
    "#Kamyar Azizzadenesheli - Purdue University \n",
    "#Pedram Hassanzadeh - Rice University \n",
    "#Karthik Kashinath - NVIDIA Corporation \n",
    "#Animashree Anandkumar - California Institute of Technology, NVIDIA Corporation\n",
    "\n",
    "\n",
    "# Instructions: \n",
    "# Set Nimgtot correctly\n",
    "\n",
    "import h5py\n",
    "from mpi4py import MPI\n",
    "import numpy as np\n",
    "import time\n",
    "from netCDF4 import Dataset as DS\n",
    "import os\n",
    "\n",
    "def print_hdf5_contents(name, obj):\n",
    "        print(name)\n",
    "\n",
    "def writetofile(src, dest, channel_idx, varslist, src_idx=0, frmt='nc'):\n",
    "    if os.path.isfile(src):\n",
    "        batch = 2**4\n",
    "        rank = MPI.COMM_WORLD.rank\n",
    "        Nproc = MPI.COMM_WORLD.size\n",
    "        Nimgtot = 4#src_shape[0]\n",
    "\n",
    "        Nimg = Nimgtot//Nproc\n",
    "        base = rank*Nimg\n",
    "        end = (rank+1)*Nimg if rank<Nproc - 1 else Nimgtot\n",
    "        idx = base\n",
    "\n",
    "        for variable_name in varslist[:3]:\n",
    "\n",
    "            if frmt == 'nc':\n",
    "                fsrc = DS(src, 'r', format=\"NETCDF4\").variables[variable_name]\n",
    "                print(fsrc.shape[0])\n",
    "            elif frmt == 'h5':\n",
    "                fsrc = h5py.File(src, 'r')[varslist[0]]\n",
    "            print(\"fsrc shape\", fsrc.shape)\n",
    "            fdest = h5py.File(dest, 'a', driver='mpio', comm=MPI.COMM_WORLD)\n",
    "            \n",
    "\n",
    "            start = time.time()\n",
    "            while idx<end:\n",
    "                if end - idx < batch:\n",
    "                    if len(fsrc.shape) == 4:\n",
    "                        ims = fsrc[idx:end,src_idx]\n",
    "                    else:\n",
    "                        ims = fsrc[idx:end]\n",
    "                    print(ims.shape)\n",
    "                    if 'fields' not in fdest:\n",
    "                        fdest.create_dataset('fields', \n",
    "                                             (Nimgtot, 20, 721, 1440),\n",
    "                                             dtype=fsrc.dtype)\n",
    "                    fdest['fields'][idx:end, channel_idx, :, :] = ims\n",
    "                    break\n",
    "                else:\n",
    "                    if len(fsrc.shape) == 4:\n",
    "                        ims = fsrc[idx:idx+batch,src_idx]\n",
    "                    else:\n",
    "                        ims = fsrc[idx:idx+batch]\n",
    "                    #ims = fsrc[idx:idx+batch]\n",
    "                    print(\"ims shape\", ims.shape)\n",
    "                    if 'fields' not in fdest:\n",
    "                        fdest.create_dataset('fields', \n",
    "                                             (Nimgtot, 20, 721, 1440),\n",
    "                                             dtype=fsrc.dtype)\n",
    "                    fdest['fields'][idx:idx+batch, channel_idx, :, :] = ims\n",
    "                    idx+=batch\n",
    "                    ttot = time.time() - start\n",
    "                    eta = (end - base)/((idx - base)/ttot)\n",
    "                    hrs = eta//3600\n",
    "                    mins = (eta - 3600*hrs)//60\n",
    "                    secs = (eta - 3600*hrs - 60*mins)\n",
    "\n",
    "            ttot = time.time() - start\n",
    "            hrs = ttot//3600\n",
    "            mins = (ttot - 3600*hrs)//60\n",
    "            secs = (ttot - 3600*hrs - 60*mins)\n",
    "            channel_idx += 1 \n",
    "dest = '/home/jovyan/processed.h5'\n",
    "\n",
    "src = '/home/jovyan/out1.nc'\n",
    "#u10 v10 t2m\n",
    "writetofile(src, dest, 0, ['u10'])\n",
    "writetofile(src, dest, 1, ['v10'])\n",
    "writetofile(src, dest, 2, ['t2m'])\n",
    "\n",
    "#sp mslp\n",
    "# writetofile(src, dest, 3, ['sp'])\n",
    "# writetofile(src, dest, 4, ['msl'])\n",
    "\n",
    "#t850\n",
    "# writetofile(src, dest, 5, ['t'], 1)\n",
    "\n",
    "#uvz1000\n",
    "# writetofile(src, dest, 6, ['u'], 0)\n",
    "# writetofile(src, dest, 7, ['v'], 0)\n",
    "# writetofile(src, dest, 8, ['z'], 0)\n",
    "\n",
    "#uvz850\n",
    "# writetofile(src, dest, 9, ['u'], 1)\n",
    "# writetofile(src, dest, 10, ['v'], 1)\n",
    "# writetofile(src, dest, 11, ['z'], 1)\n",
    "\n",
    "#uvz 500\n",
    "# writetofile(src, dest, 12, ['u'], 2)\n",
    "# writetofile(src, dest, 13, ['v'], 2)\n",
    "# writetofile(src, dest, 14, ['z'], 2)\n",
    "\n",
    "# #t500\n",
    "# writetofile(src, dest, 15, ['t'], 2)\n",
    "\n",
    "# #z50\n",
    "# writetofile(src, dest, 16, ['z'], 3) \n",
    "\n",
    "# #r500 \n",
    "# writetofile(src, dest, 17, ['r'], 2)\n",
    "\n",
    "# #r850\n",
    "# writetofile(src, dest, 18, ['r'], 1)\n",
    "#######\n",
    "#tcwv\n",
    "# writetofile(src, dest, 19, ['tcwv'])\n",
    "\n",
    "#sst\n",
    "#src = '/project/projectdirs/dasrepo/ERA5/oct_2021_19_31_sfc.nc'\n",
    "#writetofile(src, dest, 20, ['sst'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151520c4-70c9-497d-b537-a858d4a64f5d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "dest = '/home/jovyan/processed.h5'\n",
    "src = '/home/jovyan/out1.nc'\n",
    "\n",
    "\n",
    "datat = h5py.File(dest, 'r')['fields'][0:, range(0,20), 0:720]\n",
    "\n",
    "# autoregressive inference helper\n",
    "def inference(data_slice, model, prediction_length, idx):\n",
    "    # create memory for the different stats\n",
    "    n_out_channels = params['N_out_channels']\n",
    "    acc = torch.zeros((prediction_length, n_out_channels)).to(device, dtype=torch.float)\n",
    "    rmse = torch.zeros((prediction_length, n_out_channels)).to(device, dtype=torch.float)\n",
    "\n",
    "    # to conserve GPU mem, only save one channel (can be changed if sufficient GPU mem or move to CPU)\n",
    "    targets = torch.zeros((prediction_length, 1, img_shape_x, img_shape_y)).to(device, dtype=torch.float)\n",
    "    predictions = torch.zeros((prediction_length, 1, img_shape_x, img_shape_y)).to(device, dtype=torch.float)\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(prediction_length):\n",
    "            if i == 0:\n",
    "                print(data_slice[0:1].shape)\n",
    "                first = data_slice[0:1]\n",
    "                predictions[0,0] = first[0,idx]\n",
    "                # predict\n",
    "                future_pred = model(first)\n",
    "            else:\n",
    "                future_pred = model(future_pred) # autoregressive step\n",
    "\n",
    "            if i < prediction_length - 1:\n",
    "                predictions[i+1,0] = future_pred[0,idx]\n",
    "\n",
    "            # compute metrics using the ground truth ERA5 data as \"true\" predictions\n",
    "            # rmse[i] = weighted_rmse_channels(pred, tar) * std\n",
    "            # acc[i] = weighted_acc_channels(pred-m, tar-m)\n",
    "            # print('Predicted timestep {} of {}. {} RMS Error: {}, ACC: {}'.format(i, prediction_length, field, rmse[i,idx], acc[i,idx]))\n",
    "\n",
    "            pred = future_pred\n",
    "\n",
    "    # copy to cpu for plotting/vis\n",
    "    acc_cpu = acc.cpu().numpy()\n",
    "    rmse_cpu = rmse.cpu().numpy()\n",
    "    predictions_cpu = predictions.cpu().numpy()\n",
    "    targets_cpu = targets.cpu().numpy()\n",
    "\n",
    "    print(acc_cpu, rmse_cpu, predictions_cpu, targets_cpu)\n",
    "\n",
    "    return acc_cpu, rmse_cpu, predictions_cpu, targets_cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28cec7fb-9432-4476-8f81-d7328939e211",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "###### run inference\n",
    "datat_standardized = (datat - means)/stds # standardize the data\n",
    "datat_standardized = torch.as_tensor(datat_standardized).to(device, dtype=torch.float) # move to gpu for inference\n",
    "acc_cpu, rmse_cpu, predictions_t, targets_t = inference(datat_standardized,\n",
    "                                                            model, 20, idx=5)\n",
    "# print(means[16])\n",
    "# for i in range(20):\n",
    "#     print(datat_standardized[0][i])\n",
    "#     print(torch.min(datat_standardized[0][i]))\n",
    "#     print(torch.max(datat_standardized[0][i]))\n",
    "#     print('------------ ', i, ' -------------')\n",
    "# print(predictions_t[0])\n",
    "# for i in range(20):\n",
    "#     is_homogeneous = torch.all(datat_standardized[0][i] == datat_standardized[0][i][0])\n",
    "#     print(is_homogeneous)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import numpy as np\n",
    "\n",
    "# Create subplots with the Robinson projection centered on the Pacific (central_longitude=180)\n",
    "central_longitude = 180\n",
    "projection = ccrs.Robinson(central_longitude=central_longitude)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(15, 5), subplot_kw={'projection': projection})\n",
    "t = 4  # at 2x6 hours lead time\n",
    "\n",
    "# Define the extent of the map (in degrees)\n",
    "extent = (-180, 180, -90, 90)\n",
    "\n",
    "# Define the color limits\n",
    "vmin, vmax = -2, 1\n",
    "\n",
    "# Plot the prediction data\n",
    "ax.set_global()\n",
    "im1 = ax.imshow(np.roll(predictions_t[t, 0], shift=predictions_t.shape[-1]//2, axis=-1), \n",
    "                   transform=ccrs.PlateCarree(central_longitude=0), \n",
    "                   cmap=\"bwr\", extent=extent, origin='upper')#, vmin=vmin, vmax=vmax)\n",
    "ax.coastlines()\n",
    "# ax[0].add_feature(cfeature.BORDERS)\n",
    "ax.set_title(\"FourCastNet prediction - temperature - Oct 30 2024\")\n",
    "\n",
    "\n",
    "# Add colorbar\n",
    "fig.colorbar(im1, ax=ax, orientation='horizontal', fraction=0.046, pad=0.08)\n",
    "\n",
    "for i in np.arange(2):\n",
    "    gl = ax.gridlines(draw_labels=True, dms=True, x_inline=False, y_inline=False)\n",
    "    gl.top_labels = False\n",
    "    gl.right_labels = False\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247d9a09-4917-4ae0-86f7-d481032f1e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### run inference\n",
    "datat_standardized = (datat - means)/stds # standardize the data\n",
    "datat_standardized = torch.as_tensor(datat_standardized).to(device, dtype=torch.float) # move to gpu for inference\n",
    "acc_cpu, rmse_cpu, predictions, targets = inference(datat_standardized,\n",
    "                                                            model, 20, idx=9)\n",
    "\n",
    "# Create subplots with the Robinson projection centered on the Pacific (central_longitude=180)\n",
    "central_longitude = 180\n",
    "projection = ccrs.Robinson(central_longitude=central_longitude)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(15, 5), subplot_kw={'projection': projection})\n",
    "t = 4  # at 2x6 hours lead time\n",
    "\n",
    "# Define the extent of the map (in degrees)\n",
    "extent = (-180, 180, -90, 90)\n",
    "\n",
    "# Define the color limits\n",
    "vmin, vmax = -2, 1\n",
    "\n",
    "# Plot the prediction data\n",
    "ax.set_global()\n",
    "im1 = ax.imshow(np.roll(predictions[t, 0], shift=predictions.shape[-1]//2, axis=-1), \n",
    "                   transform=ccrs.PlateCarree(central_longitude=0), \n",
    "                   cmap=\"jet\", extent=extent, origin='upper')#, vmin=vmin, vmax=vmax)\n",
    "ax.coastlines()\n",
    "# ax[0].add_feature(cfeature.BORDERS)\n",
    "ax.set_title(\"FourCastNet prediction - u850 - Oct 30 2024\")\n",
    "\n",
    "\n",
    "# Add colorbar\n",
    "fig.colorbar(im1, ax=ax, orientation='horizontal', fraction=0.046, pad=0.08)\n",
    "\n",
    "for i in np.arange(2):\n",
    "    gl = ax.gridlines(draw_labels=True, dms=True, x_inline=False, y_inline=False)\n",
    "    gl.top_labels = False\n",
    "    gl.right_labels = False\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
